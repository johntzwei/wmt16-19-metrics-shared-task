{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import itertools\n",
    "import csv\n",
    "import io\n",
    "import pickle\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMT17 system-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6971c87e22cf24c11bbf6551af64ab13\n",
      "6971c87e22cf24c11bbf6551af64ab13\n",
      "True\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/downloads/wmt17-metrics-task-package.tgz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-9ec0e27a9bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f45f3160ff90e64f275944028739bd41'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0myours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/downloads/wmt17-metrics-task-package.tgz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmine\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0myours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0myours\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/downloads/wmt17-metrics-task-package.tgz'"
     ]
    }
   ],
   "source": [
    "mine = '6971c87e22cf24c11bbf6551af64ab13'\n",
    "yours = hashlib.md5(open('data/downloads/wmt17-submitted-data-v1.0.tgz', 'rb').read()).hexdigest()\n",
    "print(mine + '\\n' + yours)\n",
    "print(mine == yours)\n",
    "\n",
    "mine = 'f45f3160ff90e64f275944028739bd41'\n",
    "yours = hashlib.md5(open('data/downloads/wmt17-metrics-task-package.tgz', 'rb').read()).hexdigest()\n",
    "print(mine + '\\n' + yours)\n",
    "print(mine == yours)\n",
    "\n",
    "# unzip to data/\n",
    "# os.system('tar -xvf data/downloads/newstest2017-segment-level-human.tar.gz -p data/')\n",
    "# os.system('tar -xvf data/downloads/wmt17-metrics-task-package.tgz -p data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Official system-level da scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_da_sys = pd.read_csv('data/wmt17-metrics-task-package/manual-evaluation/DA-syslevel.csv', delimiter=' ', header=0)\n",
    "official_da_sys.columns = ['lp', 'score', 'system']\n",
    "official_da_sys['system'] = official_da_sys['system'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER\n",
      "WER\n",
      "CDER\n",
      "baselines.en-zh\n",
      "mteval\n",
      "TER\n"
     ]
    }
   ],
   "source": [
    "sys_scores = pd.DataFrame(data={'lp':[], 'system':[]})\n",
    "\n",
    "baseline_syss = glob.glob('data/wmt17-metrics-task-package/final-metric-scores/baselines/*.sys.*')\n",
    "\n",
    "for submission in itertools.chain(baseline_syss):\n",
    "    metric_name = submission.split('/')[-1]\n",
    "    metric_name = metric_name[:-len('.sys.score.gz')] if metric_name.endswith('.gz') else metric_name[:-len('.sys.score')]\n",
    "    print(metric_name)\n",
    "\n",
    "    if submission.endswith('.gz'):\n",
    "        hybrid_filtered = '\\n'.join(i.replace(' ', '\\t') for i in gzip.open(submission, 'rt') if 'hybrid' not in i)\n",
    "        reader = io.StringIO(hybrid_filtered)\n",
    "        metric_syss = pd.read_csv(reader, delimiter='\\t', header=None)\n",
    "    else:\n",
    "        metric_syss = pd.read_csv(open(submission, 'rt'), delimiter='\\t', header=None)\n",
    "    metric_syss.columns = ['name', 'lp', 'testset', 'system', metric_name] + list(metric_syss.columns[5:])\n",
    "    \n",
    "    # fix system names\n",
    "    metric_syss.dropna(inplace=True)\n",
    "    metric_syss['system'] = metric_syss['system'].apply(lambda x: x.split('.')[0])\n",
    "    \n",
    "    sys_scores = sys_scores.merge(metric_syss[['lp','system',metric_name]], on=['lp','system'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/wmt17-metrics-task-package/final-metric-scores/baselines/baselines.en-zh.sys_hide.score.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-02893b96a001>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# en-zh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0men_zh_sys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/wmt17-metrics-task-package/final-metric-scores/baselines/baselines.en-zh.sys_hide.score.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0men_zh_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'testset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'system'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0men_zh_sys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_zh_sys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0men_zh_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hybrid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0men_zh_sys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'system'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_zh_sys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'system'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/notebook/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/notebook/lib/python3.8/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/wmt17-metrics-task-package/final-metric-scores/baselines/baselines.en-zh.sys_hide.score.gz'"
     ]
    }
   ],
   "source": [
    "# en-zh\n",
    "en_zh_sys = pd.read_csv(gzip.open('data/wmt17-metrics-task-package/final-metric-scores/baselines/baselines.en-zh.sys_hide.score.gz', 'rt'), delimiter='\\t', header=None)\n",
    "en_zh_sys.columns = ['metric', 'lp', 'testset', 'system', 'score']\n",
    "en_zh_sys = en_zh_sys[~en_zh_sys.system.str.contains('hybrid')]\n",
    "en_zh_sys['system'] = en_zh_sys['system'].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "\n",
    "for metric_name in en_zh_sys['metric'].unique():\n",
    "    if metric_name in ['chrF']:\n",
    "        continue\n",
    "    print(metric_name)\n",
    "        \n",
    "    metric_syss = en_zh_sys[en_zh_sys.metric == metric_name]\n",
    "    metric_syss.columns = ['metric', 'lp', 'testset', 'system', metric_name]\n",
    "    sys_scores = sys_scores.merge(metric_syss[['lp','system',metric_name]], on=['lp','system'], how='outer')\n",
    "    \n",
    "    # fix _x and _y\n",
    "    sys_scores[metric_name] = [ x['%s_x' % metric_name] if not np.isnan(x['%s_x' % metric_name]) else x['%s_y' % metric_name] for i, x in sys_scores.iterrows() ]\n",
    "    sys_scores = sys_scores.drop(['%s_x' % metric_name, '%s_y' % metric_name], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join metric scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_scores_da = official_da_sys.merge(sys_scores, on=['lp', 'system'], how='left')\n",
    "sys_scores_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMT17 system-level data (raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_df = []\n",
    "\n",
    "for file in glob.glob('data/wmt-human-evaluation/newstest2017-system-level-human/anon-proc-hits-sys-combined/analysis/ad-seg-scores-*.csv.gz'):\n",
    "    lp = file[-12:-7]\n",
    "    print(lp)\n",
    "    \n",
    "    df = pd.read_csv(gzip.open(file, 'rt'), delimiter=' ')\n",
    "    df['lp'] = [lp] * len(df)\n",
    "    \n",
    "    lp_df.append(df)\n",
    "raw_seg_scores_da = pd.concat(lp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sys_scores_da = raw_seg_scores_da.groupby(['lp', 'SYS'], as_index=False).mean()\n",
    "\n",
    "raw_sys_scores_da.columns = ['lp', 'system', 'sid', 'raw_score', 'score', 'N', '5']\n",
    "raw_sys_scores_da = raw_sys_scores_da[['lp', 'system', 'raw_score', 'score']]\n",
    "raw_sys_scores_da['system'] = raw_sys_scores_da['system'].apply(lambda x: x.split('.')[0])\n",
    "raw_sys_scores_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_scores_da = sys_scores_da.merge(raw_sys_scores_da[['lp','system','raw_score']])\n",
    "sys_scores_da[['lp','raw_score', 'score']].groupby('lp').corr('pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_da_sys \\\n",
    "    .groupby('lp') \\\n",
    "    ['system'] \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't be reproduced:\n",
    "# lv-en (differences +-0.002)\n",
    "# en-lv (differences +-0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys_scores_da[sys_scores_da.lp.str.endswith('en')] \\\n",
    "    .groupby('lp') \\\n",
    "    .corr()[::9] \\\n",
    "    .round(3) \\\n",
    "    .T \\\n",
    "    .sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys_scores_da[~sys_scores_da.lp.str.endswith('en')] \\\n",
    "    .groupby('lp') \\\n",
    "    .corr()[::9] \\\n",
    "    .round(3) \\\n",
    "    .T \\\n",
    "    .sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMT17 system-level (src, ref, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seg_scores_da = raw_seg_scores_da[['SYS','SID','RAW.SCR','Z.SCR','N','lp']]\n",
    "raw_seg_scores_da.columns = ['system', 'sid', 'raw_score', 'score', 'N', 'lp']\n",
    "\n",
    "raw_seg_scores_da['system'] = raw_seg_scores_da['system'].apply(lambda x: x.split('.')[0]) \n",
    "raw_seg_scores_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcs and refs\n",
    "srcs, refs, lps, sids = [], [], [], []\n",
    "for lp in sys_scores_da.lp.unique():\n",
    "    fr, to = lp[:2], lp[3:]\n",
    "    \n",
    "    refs_ = list(open('data/wmt17-submitted-data/txt/references/newstest2017-%s%s-ref.%s' % (fr, to, to)))\n",
    "    srcs_ = list(open('data/wmt17-submitted-data/txt/sources/newstest2017-%s%s-src.%s' % (fr, to, fr)))\n",
    "    sids_ = list(range(1, len(refs_)+1))\n",
    "    refs.extend(refs_)\n",
    "    srcs.extend(srcs_)\n",
    "    sids.extend(sids_)\n",
    "    \n",
    "    assert(len(refs_) == len(srcs_))\n",
    "    lps.extend([lp]*len(refs_))\n",
    "    \n",
    "src_ref_df = pd.DataFrame({'reference' : refs, 'source':srcs, 'lp': lps, 'sid': sids})\n",
    "print('# of entries before merge: %d' % len(raw_seg_scores_da))\n",
    "raw_seg_scores_da = raw_seg_scores_da.merge(src_ref_df, on=['lp','sid'], how='inner')\n",
    "print('# of entries after merge: %d' % len(raw_seg_scores_da))\n",
    "print('These two should be equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs\n",
    "lps, outs, sids, syss = [], [], [], []\n",
    "for file in glob.glob('data/wmt17-submitted-data/txt/system-outputs/newstest2017/*/*'):\n",
    "    lp = file.split('.')[-1]\n",
    "    system = file.split('.')[-3]\n",
    "    \n",
    "    # manual fixes\n",
    "    if 'tuning' in file:\n",
    "        system = file.split('.')[1]\n",
    "    elif system == 'CASICT-DCU-NMT':\n",
    "        system = 'CASICT-cons'\n",
    "    elif system == 'FBK':\n",
    "        system = 'fbk-nmt-combination'    \n",
    "    \n",
    "    outs_ = list(open(file, 'rt'))\n",
    "    sids_ = list(range(1, len(outs_)+1))\n",
    "    lps_ = len(outs_) * [lp]\n",
    "    syss_ = len(outs_) * [system]\n",
    "    \n",
    "    outs.extend(outs_)\n",
    "    sids.extend(sids_)\n",
    "    lps.extend(lps_)\n",
    "    syss.extend(syss_)\n",
    "\n",
    "out_df = pd.DataFrame({'lp': lps, 'output':outs, 'sid': sids, 'system': syss})\n",
    "print('# of entries before merge: %d' % len(raw_seg_scores_da))\n",
    "raw_seg_scores_da = raw_seg_scores_da.merge(out_df, on=['lp','sid', 'system'], how='inner')\n",
    "print('# of entries after merge: %d' % len(raw_seg_scores_da))\n",
    "print('These two should be equal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(raw_seg_scores_da, open('data/pickles/wmt17-sys_level-all.pkl', 'wb'))\n",
    "pickle.dump(sys_scores_da, open('data/pickles/wmt17-sys_level-agg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMT17 segment-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'out_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-70e413218b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseg_scores_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'system'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_scores_da\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'system'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_scores_da\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mseg_scores_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_scores_da\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'system'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'system'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mseg_scores_da\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_scores_da\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_ref_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'source'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseg_scores_da\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out_df' is not defined"
     ]
    }
   ],
   "source": [
    "seg_scores_da = pd.read_csv('data/wmt17-metrics-task-package/manual-evaluation/DA-seglevel.csv', delimiter=' ')\n",
    "seg_scores_da.columns = ['lp', 'testset', 'system', 'sid', 'score']\n",
    "seg_scores_da['system'] = seg_scores_da['system'].apply(lambda x: x.split('.')[0]) \n",
    "print(len(seg_scores_da))\n",
    "seg_scores_da = seg_scores_da.merge(out_df[['lp', 'system', 'sid', 'output']], on=['lp', 'system', 'sid'], how='inner')\n",
    "seg_scores_da = seg_scores_da.merge(src_ref_df[['lp', 'sid', 'source', 'reference']], on=['lp', 'sid'], how='inner')\n",
    "print(len(seg_scores_da))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_scores_da = seg_scores_da[['lp', 'system', 'sid', 'output', 'source', 'reference', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_scores_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_scores_da.groupby('lp').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lp</th>\n",
       "      <th>system</th>\n",
       "      <th>sid</th>\n",
       "      <th>output</th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en-zh</td>\n",
       "      <td>UU-HNMT</td>\n",
       "      <td>11</td>\n",
       "      <td>“他找到了一个公寓，他和约会一个女孩，”路易斯·卡利亚说。\\n</td>\n",
       "      <td>\"He found an apartment, he was dating a girl,\"...</td>\n",
       "      <td>Louis Galicia 告诉 KGO：“Frank找到一间公寓，同时在跟一个女孩交往。”\\n</td>\n",
       "      <td>-0.522268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-zh</td>\n",
       "      <td>jhu-nmt</td>\n",
       "      <td>28</td>\n",
       "      <td>这场纠纷导致了今年参加六次罢工的初级医生，其中包括NHS历史上第一次停工。\\n</td>\n",
       "      <td>The dispute has led to junior doctors taking p...</td>\n",
       "      <td>该纠纷已导致初级医生今年共参与六次罢工，包括英国国家医疗服务体系历史上的首次全面罢工。\\n</td>\n",
       "      <td>-0.150441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en-zh</td>\n",
       "      <td>CASICT-cons</td>\n",
       "      <td>39</td>\n",
       "      <td>我迷失了。\\n</td>\n",
       "      <td>I lost count.\\n</td>\n",
       "      <td>我记不清了。\\n</td>\n",
       "      <td>-0.330678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en-zh</td>\n",
       "      <td>online-A</td>\n",
       "      <td>49</td>\n",
       "      <td>自11月以来, 俄罗斯公众舆论也出现了转变。\\n</td>\n",
       "      <td>Russian public opinion has also turned since N...</td>\n",
       "      <td>自11月份开始，俄罗斯民意也有所扭转。\\n</td>\n",
       "      <td>0.490614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en-zh</td>\n",
       "      <td>CASICT-cons</td>\n",
       "      <td>68</td>\n",
       "      <td>安卡拉对西方感到愤怒，因为它认为对企图收购的反应是微弱的。\\n</td>\n",
       "      <td>Ankara is angry with the West for what it cons...</td>\n",
       "      <td>安卡拉对于西方世界对接管意图的微弱反应感到愤怒。\\n</td>\n",
       "      <td>-0.431865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lp       system  sid                                   output  \\\n",
       "0  en-zh      UU-HNMT   11          “他找到了一个公寓，他和约会一个女孩，”路易斯·卡利亚说。\\n   \n",
       "1  en-zh      jhu-nmt   28  这场纠纷导致了今年参加六次罢工的初级医生，其中包括NHS历史上第一次停工。\\n   \n",
       "2  en-zh  CASICT-cons   39                                  我迷失了。\\n   \n",
       "3  en-zh     online-A   49                 自11月以来, 俄罗斯公众舆论也出现了转变。\\n   \n",
       "4  en-zh  CASICT-cons   68          安卡拉对西方感到愤怒，因为它认为对企图收购的反应是微弱的。\\n   \n",
       "\n",
       "                                              source  \\\n",
       "0  \"He found an apartment, he was dating a girl,\"...   \n",
       "1  The dispute has led to junior doctors taking p...   \n",
       "2                                    I lost count.\\n   \n",
       "3  Russian public opinion has also turned since N...   \n",
       "4  Ankara is angry with the West for what it cons...   \n",
       "\n",
       "                                          reference     score  \n",
       "0  Louis Galicia 告诉 KGO：“Frank找到一间公寓，同时在跟一个女孩交往。”\\n -0.522268  \n",
       "1     该纠纷已导致初级医生今年共参与六次罢工，包括英国国家医疗服务体系历史上的首次全面罢工。\\n -0.150441  \n",
       "2                                          我记不清了。\\n -0.330678  \n",
       "3                             自11月份开始，俄罗斯民意也有所扭转。\\n  0.490614  \n",
       "4                        安卡拉对于西方世界对接管意图的微弱反应感到愤怒。\\n -0.431865  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_scores_da = pickle.load(open('data/pickles/wmt17-seg_level-agg.pkl', 'rb'))\n",
    "seg_scores_da.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lp</th>\n",
       "      <th>testset</th>\n",
       "      <th>system</th>\n",
       "      <th>sid</th>\n",
       "      <th>sentBLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>sentBLEU</td>\n",
       "      <td>cs-en</td>\n",
       "      <td>newstest2017</td>\n",
       "      <td>online-A</td>\n",
       "      <td>1</td>\n",
       "      <td>0.265386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>sentBLEU</td>\n",
       "      <td>cs-en</td>\n",
       "      <td>newstest2017</td>\n",
       "      <td>online-A</td>\n",
       "      <td>2</td>\n",
       "      <td>0.189448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>sentBLEU</td>\n",
       "      <td>cs-en</td>\n",
       "      <td>newstest2017</td>\n",
       "      <td>online-A</td>\n",
       "      <td>3</td>\n",
       "      <td>0.249669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>sentBLEU</td>\n",
       "      <td>cs-en</td>\n",
       "      <td>newstest2017</td>\n",
       "      <td>online-A</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>sentBLEU</td>\n",
       "      <td>cs-en</td>\n",
       "      <td>newstest2017</td>\n",
       "      <td>online-A</td>\n",
       "      <td>5</td>\n",
       "      <td>0.173457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name     lp       testset    system  sid  sentBLEU\n",
       "3494  sentBLEU  cs-en  newstest2017  online-A    1  0.265386\n",
       "3495  sentBLEU  cs-en  newstest2017  online-A    2  0.189448\n",
       "3496  sentBLEU  cs-en  newstest2017  online-A    3  0.249669\n",
       "3497  sentBLEU  cs-en  newstest2017  online-A    4  0.312581\n",
       "3498  sentBLEU  cs-en  newstest2017  online-A    5  0.173457"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentbleu = pd.read_csv('data/wmt17-metrics-task-package/final-metric-scores/baselines/sentence-BLEU.seg.score.gz', \n",
    "                    delimiter='\\t',\n",
    "                    header=None)\n",
    "sentbleu.columns = [ 'name', 'lp', 'testset', 'system', 'sid', 'sentBLEU' ]\n",
    "sentbleu = sentbleu[sentbleu.testset == 'newstest2017']\n",
    "sentbleu['system'] = sentbleu['system'].apply(lambda x: x.split('.')[0])\n",
    "sentbleu.drop_duplicates(inplace=True)\n",
    "sentbleu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5040\n",
      "5600\n"
     ]
    }
   ],
   "source": [
    "print(len(seg_scores_da))\n",
    "seg_scores_da = seg_scores_da.merge(sentbleu[['lp', 'system', 'sid', 'sentBLEU']], on=['lp', 'system', 'sid'], how='inner')\n",
    "print(len(seg_scores_da))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lp          \n",
       "cs-en  score    0.434955\n",
       "de-en  score    0.432482\n",
       "fi-en  score    0.571167\n",
       "lv-en  score    0.392805\n",
       "ru-en  score    0.484211\n",
       "tr-en  score    0.538433\n",
       "zh-en  score    0.511674\n",
       "Name: sentBLEU, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_scores_da[seg_scores_da.lp.str.endswith('en')].groupby('lp').corr()[1::3]['sentBLEU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lp          \n",
       "en-ru  score    0.467901\n",
       "en-zh  score    0.377060\n",
       "Name: sentBLEU, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_scores_da[~seg_scores_da.lp.str.endswith('en')].groupby('lp').corr()[1::3]['sentBLEU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(seg_scores_da, open('data/pickles/wmt17-seg_level-agg.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
