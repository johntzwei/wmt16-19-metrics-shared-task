{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import itertools\n",
    "import csv\n",
    "import io\n",
    "import pickle\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMT16 system-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = 'c983b60fa311b60c04c0293aaf1a2bc4'\n",
    "yours = hashlib.md5(open(\"data/downloads/wmt16-submitted-data-v2.tgz\", 'rb').read()).hexdigest()\n",
    "print(mine + '\\n' + yours)\n",
    "print(mine == yours)\n",
    "\n",
    "\n",
    "mine = '2acd4f1d8fcc07115cc06bcaed4ff236'\n",
    "yours = hashlib.md5(open(\"data/downloads/wmt16-metrics-results.tar.gz\", 'rb').read()).hexdigest()\n",
    "print(mine + '\\n' + yours)\n",
    "print(mine == yours)\n",
    "\n",
    "# unzip to data/\n",
    "if False:\n",
    "    os.system('tar -xvf data/downloads/wmt16-submitted-data-v2.tgz -p data/')\n",
    "    os.system('tar -xvf data/downloads/wmt16-metrics-results.tar.gz -p data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate system-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_files = [ i for i in glob.glob('data/wmt16-metrics-results/sys-level-results/standard/results-official/newstest2016*') if not 'noDA' in i ]\n",
    "lp_df = []\n",
    "\n",
    "for file in da_files:\n",
    "    lp = file[-8:-4]\n",
    "    lp = lp[0:2] + '-' + lp[2:]\n",
    "    \n",
    "    df = pd.read_csv(file, delimiter=' ')\n",
    "    df['lp'] = lp\n",
    "    \n",
    "    lp_df.append(df)\n",
    "sys_scores_da = pd.concat(lp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = {'DA':'score', 'MT':'system', 'mtevalBLEU':'BLEU', 'mtevalNIST':'NIST', 'mosesCDER':'CDER', 'mosesPER':'PER', 'mosesWER':'WER'}\n",
    "sys_scores_da.columns = [ replace[i] if i in replace else i for i in sys_scores_da.columns ]\n",
    "\n",
    "sys_scores_da = sys_scores_da[['lp', 'system', 'BLEU', 'NIST', 'CDER', 'PER', 'WER', 'TER', 'score']]\n",
    "sys_scores_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMT16 system-level data (all/raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_df = []\n",
    "\n",
    "for file in glob.glob('data/wmt-human-evaluation/da-human-judgments/ad-seg-scores-*.csv'):\n",
    "    lp = file[-9:-4]\n",
    "    \n",
    "    df = pd.read_csv(file, delimiter=' ')\n",
    "    df['lp'] = [lp] * len(df)\n",
    "    \n",
    "    lp_df.append(df)\n",
    "raw_seg_scores_da = pd.concat(lp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = raw_seg_scores_da.groupby(['lp', 'SYS'], as_index=False).count()['N']\n",
    "raw_sys_scores_da = raw_seg_scores_da.groupby(['lp', 'SYS'], as_index=False).mean()\n",
    "raw_sys_scores_da['N'] = N\n",
    "\n",
    "raw_sys_scores_da.columns = ['lp', 'system', 'sid', 'raw_score', 'score', 'N', '5']\n",
    "raw_sys_scores_da = raw_sys_scores_da[['lp', 'system', 'raw_score', 'score', 'N']]\n",
    "raw_sys_scores_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_scores_da = sys_scores_da.merge(raw_sys_scores_da[['lp','system','raw_score']])\n",
    "sys_scores_da[['lp','raw_score', 'score']].groupby('lp').corr('pearson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMT16 (src, ref, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcs and refs\n",
    "srcs, refs, lps, sids = [], [], [], []\n",
    "for lp in sys_scores_da.lp.unique():\n",
    "    fr, to = lp[:2], lp[3:]\n",
    "    \n",
    "    refs_ = list(open('data/wmt16-submitted-data/txt/references/newstest2016-%s%s-ref.%s' % (fr, to, to)))\n",
    "    srcs_ = list(open('data/wmt16-submitted-data/txt/sources/newstest2016-%s%s-src.%s' % (fr, to, fr)))\n",
    "    sids_ = list(range(1, len(refs_)+1))\n",
    "    refs.extend(refs_)\n",
    "    srcs.extend(srcs_)\n",
    "    sids.extend(sids_)\n",
    "    \n",
    "    assert(len(refs_) == len(srcs_))\n",
    "    lps.extend([lp]*len(refs_))\n",
    "    \n",
    "df = pd.DataFrame({'reference' : refs, 'source':srcs, 'lp': lps, 'SID': sids})\n",
    "print('# of entries before merge: %d' % len(raw_seg_scores_da))\n",
    "raw_seg_scores_da = raw_seg_scores_da.merge(df, on=['lp','SID'], how='inner')\n",
    "print('# of entries after merge: %d' % len(raw_seg_scores_da))\n",
    "print('These two should be equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outs\n",
    "lps, outs, sids, syss = [], [], [], []\n",
    "for file in glob.glob('data/wmt16-submitted-data/txt/system-outputs/newstest2016/*/*'):\n",
    "    lp = file.split('.')[-1]\n",
    "    system = file.split('.')[-3]\n",
    "    \n",
    "    outs_ = list(open(file, 'rt'))\n",
    "    sids_ = list(range(1, len(outs_)+1))\n",
    "    lps_ = len(outs_) * [lp]\n",
    "    syss_ = len(outs_) * [system]\n",
    "    \n",
    "    outs.extend(outs_)\n",
    "    sids.extend(sids_)\n",
    "    lps.extend(lps_)\n",
    "    syss.extend(syss_)\n",
    "\n",
    "df = pd.DataFrame({'lp': lps, 'output':outs, 'SID': sids, 'SYS': syss})\n",
    "print('# of entries before merge: %d' % len(raw_seg_scores_da))\n",
    "raw_seg_scores_da = raw_seg_scores_da.merge(df, on=['lp','SID', 'SYS'], how='inner')\n",
    "print('# of entries after merge: %d' % len(raw_seg_scores_da))\n",
    "print('These two should be equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_seg_scores_da.columns = ['system', 'sid', 'raw_score', 'score', 'N', 'nan', 'lp', 'reference', 'source', 'output']\n",
    "raw_seg_scores_da = raw_seg_scores_da[['system', 'sid', 'raw_score', 'score', 'N', 'lp', 'reference', 'source', 'output']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_scores_da.groupby('lp') \\\n",
    "    ['lp'] \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys_scores_da[sys_scores_da.lp.str.endswith('en')] \\\n",
    "    .groupby('lp') \\\n",
    "    .corr()[6::8] \\\n",
    "    .round(3) \\\n",
    "    .T \\\n",
    "    .sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys_scores_da[~sys_scores_da.lp.str.endswith('en')] \\\n",
    "    .groupby('lp') \\\n",
    "    .corr()[6::8] \\\n",
    "    .round(3) \\\n",
    "    .T \\\n",
    "    .sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(raw_seg_scores_da, open('data/pickles/wmt16-sys_level-all.pkl', 'wb'))\n",
    "pickle.dump(sys_scores_da, open('data/pickles/wmt16-sys_level-agg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WMT16 segment-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_files = [ i for i in glob.glob('data/wmt16-metrics-results/seg-level-results/da-results/metrics.*.csv') if not 'noDA' in i ]\n",
    "lp_df = []\n",
    "\n",
    "for file in da_files:\n",
    "    lp = file[-9:-4]\n",
    "    \n",
    "    df = pd.read_csv(file, delimiter=' ')\n",
    "    df['lp'] = lp\n",
    "    lp_df.append(df)\n",
    "    \n",
    "    df['source'] = list(open('data/wmt16-metrics-results/seg-level-results/da-results/src.%s' % lp, 'rt'))\n",
    "    df['output'] = list(open('data/wmt16-metrics-results/seg-level-results/da-results/snt.%s' % lp, 'rt'))\n",
    "    df['reference'] = list(open('data/wmt16-metrics-results/seg-level-results/da-results/ref.%s' % lp, 'rt'))\n",
    "    \n",
    "seg_scores_da = pd.concat(lp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cs-en</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de-en</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en-ru</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fi-en</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ro-en</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru-en</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr-en</th>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SID\n",
       "lp        \n",
       "cs-en  560\n",
       "de-en  560\n",
       "en-ru  560\n",
       "fi-en  560\n",
       "ro-en  560\n",
       "ru-en  560\n",
       "tr-en  560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_scores_da.groupby('lp').count()[['SID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lp</th>\n",
       "      <th>system</th>\n",
       "      <th>sid</th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>output</th>\n",
       "      <th>sentBLEU</th>\n",
       "      <th>chrF1</th>\n",
       "      <th>BEER</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>jhu-pbmt</td>\n",
       "      <td>1092</td>\n",
       "      <td>To recall, Luis Enrique trained the \"wolves\" d...</td>\n",
       "      <td>Напомним, что Луис Энрике тренировал \"волков\" ...</td>\n",
       "      <td>Напомним, Луис Энрике тренировал \"волков\" в се...</td>\n",
       "      <td>0.273012</td>\n",
       "      <td>73.3096</td>\n",
       "      <td>0.658724</td>\n",
       "      <td>0.363122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>online-G</td>\n",
       "      <td>750</td>\n",
       "      <td>It could have had it last night.\\n</td>\n",
       "      <td>Она могла получить компресс вчера вечером.\\n</td>\n",
       "      <td>Оно смогло иметь его вчера вечером.\\n</td>\n",
       "      <td>0.076668</td>\n",
       "      <td>61.0558</td>\n",
       "      <td>0.449425</td>\n",
       "      <td>-0.450232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>AFRL-MITLL-phrase-based</td>\n",
       "      <td>2786</td>\n",
       "      <td>Police asked the caller his name, but he didn'...</td>\n",
       "      <td>Полиция поинтересовалась именем звонившего, но...</td>\n",
       "      <td>Полиция попросила звонящему его имя, но он не ...</td>\n",
       "      <td>0.252464</td>\n",
       "      <td>69.0143</td>\n",
       "      <td>0.542931</td>\n",
       "      <td>0.113451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>LIMSI</td>\n",
       "      <td>250</td>\n",
       "      <td>In a report this week, Morgan Stanley analyst ...</td>\n",
       "      <td>В отчете, опубликованном на этой неделе, Том К...</td>\n",
       "      <td>В отчете, опубликованном на этой неделе, по оц...</td>\n",
       "      <td>0.531697</td>\n",
       "      <td>69.1746</td>\n",
       "      <td>0.611773</td>\n",
       "      <td>-0.257524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en-ru</td>\n",
       "      <td>AFRL-MITLL-phrase-based</td>\n",
       "      <td>88</td>\n",
       "      <td>There is a potential investor who is ready to ...</td>\n",
       "      <td>Есть потенциальный инвестор, готовый вложить в...</td>\n",
       "      <td>Есть потенциальный инвестор, который готов вло...</td>\n",
       "      <td>0.097414</td>\n",
       "      <td>61.5655</td>\n",
       "      <td>0.485377</td>\n",
       "      <td>-0.695001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>de-en</td>\n",
       "      <td>uedin-syntax</td>\n",
       "      <td>2921</td>\n",
       "      <td>Ursprünglich hatte dieser Punkt auf dem nicht-...</td>\n",
       "      <td>Originally this point was scheduled as a part ...</td>\n",
       "      <td>This point had originally stood on the non pub...</td>\n",
       "      <td>0.316149</td>\n",
       "      <td>60.5717</td>\n",
       "      <td>0.590319</td>\n",
       "      <td>-0.893829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>de-en</td>\n",
       "      <td>KIT</td>\n",
       "      <td>2090</td>\n",
       "      <td>Metcash lehnte es ab, öffentlich auf die Komme...</td>\n",
       "      <td>Metcash has declined to respond publicly to Mr...</td>\n",
       "      <td>Metcash refused to respond publicly to the com...</td>\n",
       "      <td>0.772290</td>\n",
       "      <td>89.4910</td>\n",
       "      <td>0.832221</td>\n",
       "      <td>1.019740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>de-en</td>\n",
       "      <td>KIT</td>\n",
       "      <td>2158</td>\n",
       "      <td>Jede Wohneinheit hat zwei Schlafzimmer, ein Ba...</td>\n",
       "      <td>Each living unit has two bedrooms, one bathroo...</td>\n",
       "      <td>Each housing unit has two bedrooms, a bath, a ...</td>\n",
       "      <td>0.526244</td>\n",
       "      <td>78.9509</td>\n",
       "      <td>0.735487</td>\n",
       "      <td>0.934524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>de-en</td>\n",
       "      <td>KIT</td>\n",
       "      <td>2097</td>\n",
       "      <td>Wir brauchen wirklich, wirklich die Unterstütz...</td>\n",
       "      <td>We really, really need the support of Celtic b...</td>\n",
       "      <td>We really need to really support Celtic becaus...</td>\n",
       "      <td>0.292517</td>\n",
       "      <td>61.0922</td>\n",
       "      <td>0.645676</td>\n",
       "      <td>0.867003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>de-en</td>\n",
       "      <td>uedin-pbmt</td>\n",
       "      <td>1326</td>\n",
       "      <td>Tausende verzweifelte Flüchtlinge stecken inzw...</td>\n",
       "      <td>Thousands of desperate refugees are currently ...</td>\n",
       "      <td>Thousands of desperate refugees are stuck in t...</td>\n",
       "      <td>0.099947</td>\n",
       "      <td>35.2979</td>\n",
       "      <td>0.391452</td>\n",
       "      <td>-0.616444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3920 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lp                   system   sid  \\\n",
       "0    en-ru                 jhu-pbmt  1092   \n",
       "1    en-ru                 online-G   750   \n",
       "2    en-ru  AFRL-MITLL-phrase-based  2786   \n",
       "3    en-ru                    LIMSI   250   \n",
       "4    en-ru  AFRL-MITLL-phrase-based    88   \n",
       "..     ...                      ...   ...   \n",
       "555  de-en             uedin-syntax  2921   \n",
       "556  de-en                      KIT  2090   \n",
       "557  de-en                      KIT  2158   \n",
       "558  de-en                      KIT  2097   \n",
       "559  de-en               uedin-pbmt  1326   \n",
       "\n",
       "                                                source  \\\n",
       "0    To recall, Luis Enrique trained the \"wolves\" d...   \n",
       "1                   It could have had it last night.\\n   \n",
       "2    Police asked the caller his name, but he didn'...   \n",
       "3    In a report this week, Morgan Stanley analyst ...   \n",
       "4    There is a potential investor who is ready to ...   \n",
       "..                                                 ...   \n",
       "555  Ursprünglich hatte dieser Punkt auf dem nicht-...   \n",
       "556  Metcash lehnte es ab, öffentlich auf die Komme...   \n",
       "557  Jede Wohneinheit hat zwei Schlafzimmer, ein Ba...   \n",
       "558  Wir brauchen wirklich, wirklich die Unterstütz...   \n",
       "559  Tausende verzweifelte Flüchtlinge stecken inzw...   \n",
       "\n",
       "                                             reference  \\\n",
       "0    Напомним, что Луис Энрике тренировал \"волков\" ...   \n",
       "1         Она могла получить компресс вчера вечером.\\n   \n",
       "2    Полиция поинтересовалась именем звонившего, но...   \n",
       "3    В отчете, опубликованном на этой неделе, Том К...   \n",
       "4    Есть потенциальный инвестор, готовый вложить в...   \n",
       "..                                                 ...   \n",
       "555  Originally this point was scheduled as a part ...   \n",
       "556  Metcash has declined to respond publicly to Mr...   \n",
       "557  Each living unit has two bedrooms, one bathroo...   \n",
       "558  We really, really need the support of Celtic b...   \n",
       "559  Thousands of desperate refugees are currently ...   \n",
       "\n",
       "                                                output  sentBLEU    chrF1  \\\n",
       "0    Напомним, Луис Энрике тренировал \"волков\" в се...  0.273012  73.3096   \n",
       "1                Оно смогло иметь его вчера вечером.\\n  0.076668  61.0558   \n",
       "2    Полиция попросила звонящему его имя, но он не ...  0.252464  69.0143   \n",
       "3    В отчете, опубликованном на этой неделе, по оц...  0.531697  69.1746   \n",
       "4    Есть потенциальный инвестор, который готов вло...  0.097414  61.5655   \n",
       "..                                                 ...       ...      ...   \n",
       "555  This point had originally stood on the non pub...  0.316149  60.5717   \n",
       "556  Metcash refused to respond publicly to the com...  0.772290  89.4910   \n",
       "557  Each housing unit has two bedrooms, a bath, a ...  0.526244  78.9509   \n",
       "558  We really need to really support Celtic becaus...  0.292517  61.0922   \n",
       "559  Thousands of desperate refugees are stuck in t...  0.099947  35.2979   \n",
       "\n",
       "         BEER     score  \n",
       "0    0.658724  0.363122  \n",
       "1    0.449425 -0.450232  \n",
       "2    0.542931  0.113451  \n",
       "3    0.611773 -0.257524  \n",
       "4    0.485377 -0.695001  \n",
       "..        ...       ...  \n",
       "555  0.590319 -0.893829  \n",
       "556  0.832221  1.019740  \n",
       "557  0.735487  0.934524  \n",
       "558  0.645676  0.867003  \n",
       "559  0.391452 -0.616444  \n",
       "\n",
       "[3920 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace = {'HUMAN.Z':'score', 'SID':'sid', 'MT':'system', 'mtevalBLEU':'BLEU', 'mtevalNIST':'NIST', 'mosesCDER':'CDER', 'mosesPER':'PER', 'mosesWER':'WER'}\n",
    "seg_scores_da.columns = [ replace[i] if i in replace else i for i in seg_scores_da.columns ]\n",
    "seg_scores_da = seg_scores_da[['lp', 'system', 'sid', 'source', 'reference', 'output', 'sentBLEU', 'chrF1', 'BEER',  'score']]\n",
    "seg_scores_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lp             \n",
       "cs-en  sid        -0.024384\n",
       "       sentBLEU    0.556577\n",
       "       chrF1       0.643857\n",
       "       BEER        0.661487\n",
       "       score       1.000000\n",
       "de-en  sid        -0.022854\n",
       "       sentBLEU    0.483888\n",
       "       chrF1       0.451662\n",
       "       BEER        0.470757\n",
       "       score       1.000000\n",
       "en-ru  sid         0.055816\n",
       "       sentBLEU    0.550092\n",
       "       chrF1       0.641864\n",
       "       BEER        0.665764\n",
       "       score       1.000000\n",
       "fi-en  sid        -0.012614\n",
       "       sentBLEU    0.448357\n",
       "       chrF1       0.454240\n",
       "       BEER        0.461745\n",
       "       score       1.000000\n",
       "ro-en  sid        -0.133624\n",
       "       sentBLEU    0.498979\n",
       "       chrF1       0.570245\n",
       "       BEER        0.551429\n",
       "       score       1.000000\n",
       "ru-en  sid        -0.022056\n",
       "       sentBLEU    0.501937\n",
       "       chrF1       0.521555\n",
       "       BEER        0.532879\n",
       "       score       1.000000\n",
       "tr-en  sid         0.029222\n",
       "       sentBLEU    0.531602\n",
       "       chrF1       0.550505\n",
       "       BEER        0.544962\n",
       "       score       1.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_scores_da.groupby('lp').corr()['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The de-en and fi-en columns are switched comparing our results to the paper. I will assume there is a mistake in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(seg_scores_da, open('data/pickles/wmt16-seg_level-agg.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
